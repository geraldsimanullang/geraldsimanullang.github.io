---
title: "Image Classification of Rock-paper-scissors Hand-shaped Pictures"
excerpt: "Built a Convolutional Neural Network (CNN) machine learning model with an accuracy >96% for classifying images of 
rock-paper-scissors hand-shaped pictures using the TensorFlow and Keras libraries <br/><img src=''>"
collection: portfolio
---

Hey everyone! This project is the final assignment for my Dicoding machine learning course. 
We had to make a smart thing using TensorFlow and Keras - a Convolutional Neural Network (CNN). 
What does it do? It looks at hand pictures and decides if it's showing rock, paper, or scissors. Cool part? 
Got a perfect 5/5 for it. <br/><br/>

Here are the requirements for this task: <br/>
<ul>
    <li><b>No Plagiarism!</b></li>
    <li>The dataset must be divided into a train set and a validation set.</li>
    <li>Image augmentation must be implemented.</li>
    <li>Utilize an image data generator.</li>
    <li>The model must be implemented using the sequential model.</li>
    <li>Model training should not exceed 30 minutes.</li>
    <li>The program is to be executed on Google Colaboratory.</li>
    <li>The model's accuracy should be a minimum of 85%.</li>
    <li>It should be capable of predicting images uploaded to Colab.</li>
</ul> <br/>

Criteria for Achieving a 5/5 Rating:<br/>
<ul>
    <li>All requirements must be fulfilled.</li>
    <li>Accuracy above 96%.</li>
    <li>Utilize three or more techniques not covered in the module.</li>
</ul><br/>

As mentioned in the requirements, this work was performed in <b>Google Colab</b>. 
In this post, I will provide a brief summary of each step in the project.
You can view the complete code <a href="https://github.com/geraldsimanullang/Image-classification-of-rock-paper-scissors-hand-shaped-pictures/blob/53b0ce1a5866725f304dd5a3bd7a37e493ef942f/Rock_paper_scissors_hand_image_classification.ipynb" target="_blank">here</a><br/>
<br/>
Steps of this project are as follows:
<ol>
    <li>Data preparation</li>
    <li>Data preprocessing</li>
    <li>Visualization of training data samples</li>
    <li>Sequential modeling</li>
    <li>Customizing callbacks</li>
    <li>Model training</li>
    <li>Prediction on new data</li>
</ol><br/>

Now, let's get into the project! ðŸš€<br/>

<h2>Data preparation</h2>
The first stage is data preparation. In this stage, the initial step involves downloading and importing data into Google Colab. 
The dataset used must be the one provided by Dicoding. To view the dataset, please click 
<a href"https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip" target="_blank">here</a>.<br/><br/>

The provided dataset is in .zip format. After downloading, the next step is to extract the zip file. 
The processes in this data preparation stage use the os, zipfile, and pathlib libraries. 
<b>The final result</b> of this process is a dataset containing <b>2188 images.</b><br/>

<h2>Data preprocessing</h2>
The next stage is the data preprocessing process. This stage includes <b>image augmentatio</b>n and 
<b>dividing the dataset</b> into test and validation datasets. 
These processes utilize the TensorFlow library, and then the Numpy library is employed to calculate the number of 
data for each criterion in the train dataset. Number of data per criteria in training dataset are as follows: 
'paper': 428, 'rock': 436, 'scissors': 450

<h2>Training data sample visualization</h2>
This stage is optional. Here, I perform visualization to observe 15 sample images from the training dataset using the Matplotlib library.
The results are as follows: <br/>
<p align="center">
    <img src="https://github.com/geraldsimanullang/Image-classification-of-rock-paper-scissors-hand-shaped-pictures/assets/154493278/6f52c521-d6a4-4d68-82bd-2e5be139deaa">
</p><br/>

<h3>Sequential Modelling</h3>
